{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Part 4 - Solution Reuse"
      ],
      "metadata": {
        "id": "YPk6fd1iEm9g"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wF3ZQc3uEaOR",
        "outputId": "b7394d32-58d5-45c7-9900-97f88f340a6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import pickle\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from typing import Dict, List, Tuple, Optional, Counter\n",
        "from collections import Counter, defaultdict\n",
        "import logging\n",
        "\n",
        "# Machine Learning Libraries\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# BERT and Transformers\n",
        "try:\n",
        "    from transformers import AutoTokenizer, AutoModel\n",
        "    import torch\n",
        "    TRANSFORMERS_AVAILABLE = True\n",
        "except ImportError:\n",
        "    print(\"‚ö†Ô∏è Transformers not available. Install with: pip install transformers torch\")\n",
        "    TRANSFORMERS_AVAILABLE = False\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)"
      ],
      "metadata": {
        "id": "LOQscNmpE9MS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ekstrak Solusi"
      ],
      "metadata": {
        "id": "YpIjscIyGUYh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# i. EKSTRAK SOLUSI\n",
        "# 1. Dari kasus top-k, ambil amar putusan atau ringkasan dakwaan\n",
        "# 2. Simpan di struktur: {case_id: solusi_text}\n",
        "# ============================================================================\n",
        "\n",
        "class RetrievalSystem:\n",
        "    \"\"\"\n",
        "    Sistem retrieval untuk mendukung solution reuse\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, base_dir=\"/content/drive/MyDrive/perdagangan_orang\"):\n",
        "        self.base_dir = base_dir\n",
        "        self.vectors_dir = os.path.join(base_dir, \"data\", \"vectors\")\n",
        "\n",
        "        # Components\n",
        "        self.tfidf_vectorizer = None\n",
        "        self.case_vectors_tfidf = None\n",
        "        self.case_ids = []\n",
        "\n",
        "        self.load_components()\n",
        "\n",
        "    def load_components(self) -> bool:\n",
        "        \"\"\"Load retrieval components\"\"\"\n",
        "        print(\"üîç Loading retrieval components...\")\n",
        "\n",
        "        # Find best vector file\n",
        "        vector_files = [f for f in os.listdir(self.vectors_dir) if f.endswith('.pkl')]\n",
        "\n",
        "        best_file = None\n",
        "        best_vocab_size = 0\n",
        "\n",
        "        for vf in vector_files:\n",
        "            if 'tfidf' in vf.lower():\n",
        "                try:\n",
        "                    with open(os.path.join(self.vectors_dir, vf), 'rb') as f:\n",
        "                        data = pickle.load(f)\n",
        "\n",
        "                    if 'vectorizer' in data:\n",
        "                        vocab_size = len(data['vectorizer'].get_feature_names_out())\n",
        "                        if vocab_size > best_vocab_size:\n",
        "                            best_vocab_size = vocab_size\n",
        "                            best_file = vf\n",
        "                except:\n",
        "                    continue\n",
        "\n",
        "        if best_file:\n",
        "            file_path = os.path.join(self.vectors_dir, best_file)\n",
        "            with open(file_path, 'rb') as f:\n",
        "                data = pickle.load(f)\n",
        "\n",
        "            self.tfidf_vectorizer = data['vectorizer']\n",
        "            self.case_vectors_tfidf = data['vectors']\n",
        "            self.case_ids = data['case_ids']\n",
        "\n",
        "            if hasattr(self.case_vectors_tfidf, 'toarray'):\n",
        "                self.case_vectors_tfidf = self.case_vectors_tfidf.toarray()\n",
        "\n",
        "            print(f\"‚úÖ Loaded: {len(self.case_ids)} cases, {best_vocab_size:,} vocab\")\n",
        "            return True\n",
        "\n",
        "        return False\n",
        "\n",
        "    def retrieve(self, query: str, k: int = 5) -> List[str]:\n",
        "        \"\"\"Retrieve top-k similar cases\"\"\"\n",
        "        if not self.tfidf_vectorizer or self.case_vectors_tfidf is None:\n",
        "            return []\n",
        "\n",
        "        # Preprocess query\n",
        "        processed_query = query.lower().strip()\n",
        "        processed_query = re.sub(r'\\s+', ' ', processed_query)\n",
        "\n",
        "        # Compute query vector\n",
        "        query_vector = self.tfidf_vectorizer.transform([processed_query])\n",
        "\n",
        "        if query_vector.nnz == 0:\n",
        "            return []\n",
        "\n",
        "        # Compute similarities\n",
        "        query_dense = query_vector.toarray() if hasattr(query_vector, 'toarray') else query_vector\n",
        "        similarities = cosine_similarity(query_dense, self.case_vectors_tfidf).flatten()\n",
        "\n",
        "        # Return top-k case_ids\n",
        "        top_indices = np.argsort(similarities)[::-1][:k]\n",
        "        return [self.case_ids[idx] for idx in top_indices]\n",
        "\n",
        "    def retrieve_with_scores(self, query: str, k: int = 5) -> List[Tuple[str, float]]:\n",
        "        \"\"\"Retrieve with similarity scores\"\"\"\n",
        "        if not self.tfidf_vectorizer or self.case_vectors_tfidf is None:\n",
        "            return []\n",
        "\n",
        "        processed_query = query.lower().strip()\n",
        "        query_vector = self.tfidf_vectorizer.transform([processed_query])\n",
        "\n",
        "        if query_vector.nnz == 0:\n",
        "            return []\n",
        "\n",
        "        query_dense = query_vector.toarray() if hasattr(query_vector, 'toarray') else query_vector\n",
        "        similarities = cosine_similarity(query_dense, self.case_vectors_tfidf).flatten()\n",
        "\n",
        "        top_indices = np.argsort(similarities)[::-1][:k]\n",
        "\n",
        "        results = []\n",
        "        for idx in top_indices:\n",
        "            case_id = self.case_ids[idx]\n",
        "            score = similarities[idx]\n",
        "            results.append((case_id, float(score)))\n",
        "\n",
        "        return results\n",
        "\n",
        "class SolutionExtractor:\n",
        "    \"\"\"\n",
        "    i. Ekstrak Solusi dari kasus top-k\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, base_dir=\"/content/drive/MyDrive/perdagangan_orang\"):\n",
        "        self.base_dir = base_dir\n",
        "        self.raw_dir = os.path.join(base_dir, \"CLEANED\")\n",
        "        self.processed_dir = os.path.join(base_dir, \"data\", \"processed\")\n",
        "\n",
        "        # Storage untuk solusi\n",
        "        self.case_solutions = {}  # {case_id: solusi_text}\n",
        "        self.case_metadata = {}\n",
        "\n",
        "        print(\"üìÑ i. EKSTRAK SOLUSI\")\n",
        "\n",
        "    def load_case_metadata(self) -> bool:\n",
        "        \"\"\"Load metadata kasus dari cases.csv\"\"\"\n",
        "        cases_file = os.path.join(self.processed_dir, \"cases.csv\")\n",
        "\n",
        "        if not os.path.exists(cases_file):\n",
        "            print(\"‚ùå cases.csv not found\")\n",
        "            return False\n",
        "\n",
        "        try:\n",
        "            df = pd.read_csv(cases_file, encoding='utf-8')\n",
        "\n",
        "            for _, row in df.iterrows():\n",
        "                filename = row['nama_file']\n",
        "                case_id = filename.replace('.txt', '') if filename.endswith('.txt') else filename\n",
        "\n",
        "                self.case_metadata[case_id] = {\n",
        "                    'putusan': row.get('putusan', ''),\n",
        "                    'jenis_perkara': row.get('jenis_perkara', ''),\n",
        "                    'vonis': row.get('vonis', ''),\n",
        "                    'hukuman_pidana': row.get('hukuman_pidana', ''),\n",
        "                    'hukuman_denda': row.get('hukuman_denda', ''),\n",
        "                    'dakwaan': row.get('dakwaan', ''),\n",
        "                    'pasal_yang_dilanggar': row.get('pasal_yang_dilanggar', '')\n",
        "                }\n",
        "\n",
        "            print(f\"‚úÖ Loaded metadata for {len(self.case_metadata)} cases\")\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error loading metadata: {e}\")\n",
        "            return False\n",
        "\n",
        "    def extract_solution_from_text(self, text: str) -> str:\n",
        "        \"\"\"Ekstrak amar putusan atau ringkasan dari teks\"\"\"\n",
        "        if not text:\n",
        "            return \"\"\n",
        "\n",
        "        text_lower = text.lower()\n",
        "\n",
        "        # Pattern untuk mencari amar putusan\n",
        "        putusan_patterns = [\n",
        "            r'(amar\\s+putusan[:\\s].*?)(?:\\n\\n|\\Z)',\n",
        "            r'(mengadili[:\\s].*?)(?:\\n\\n|\\Z)',\n",
        "            r'(memutuskan[:\\s].*?)(?:\\n\\n|\\Z)',\n",
        "            r'(menjatuhkan\\s+pidana[:\\s].*?)(?:\\n\\n|\\Z)',\n",
        "            r'(menghukum\\s+terdakwa[:\\s].*?)(?:\\n\\n|\\Z)'\n",
        "        ]\n",
        "\n",
        "        # Cari pattern putusan\n",
        "        for pattern in putusan_patterns:\n",
        "            matches = re.findall(pattern, text_lower, re.DOTALL | re.IGNORECASE)\n",
        "            if matches:\n",
        "                solution = matches[0].strip()\n",
        "                # Bersihkan dan ambil bagian penting\n",
        "                solution = re.sub(r'\\s+', ' ', solution)\n",
        "                solution = solution[:500]  # Batasi panjang\n",
        "                return solution\n",
        "\n",
        "        # Fallback: cari kalimat dengan kata kunci hukuman\n",
        "        hukuman_patterns = [\n",
        "            r'([^.]*(?:hukuman|pidana|denda|penjara|kurungan)[^.]*\\.)',\n",
        "            r'([^.]*(?:vonis|putusan|memutuskan)[^.]*\\.)',\n",
        "            r'([^.]*(?:terbukti|tidak terbukti)[^.]*\\.)'\n",
        "        ]\n",
        "\n",
        "        for pattern in hukuman_patterns:\n",
        "            matches = re.findall(pattern, text_lower)\n",
        "            if matches:\n",
        "                return matches[0].strip()[:300]\n",
        "\n",
        "        # Fallback terakhir: ambil bagian tengah dokumen\n",
        "        lines = text.split('\\n')\n",
        "        middle_start = len(lines) // 3\n",
        "        middle_end = 2 * len(lines) // 3\n",
        "        middle_text = ' '.join(lines[middle_start:middle_end])\n",
        "\n",
        "        return middle_text[:200].strip()\n",
        "\n",
        "    def create_solution_from_metadata(self, case_id: str) -> str:\n",
        "        \"\"\"Buat solusi dari metadata yang tersedia\"\"\"\n",
        "        if case_id not in self.case_metadata:\n",
        "            return \"Solusi tidak tersedia\"\n",
        "\n",
        "        meta = self.case_metadata[case_id]\n",
        "        solution_parts = []\n",
        "\n",
        "        # Jenis perkara\n",
        "        if meta['jenis_perkara']:\n",
        "            solution_parts.append(f\"Jenis: {meta['jenis_perkara']}\")\n",
        "\n",
        "        # Putusan\n",
        "        if meta['putusan']:\n",
        "            solution_parts.append(f\"Putusan: {meta['putusan']}\")\n",
        "\n",
        "        # Vonis\n",
        "        if meta['vonis']:\n",
        "            solution_parts.append(f\"Vonis: {meta['vonis']}\")\n",
        "\n",
        "        # Hukuman\n",
        "        if meta['hukuman_pidana']:\n",
        "            solution_parts.append(f\"Hukuman: {meta['hukuman_pidana']}\")\n",
        "\n",
        "        if meta['hukuman_denda']:\n",
        "            solution_parts.append(f\"Denda: {meta['hukuman_denda']}\")\n",
        "\n",
        "        # Pasal\n",
        "        if meta['pasal_yang_dilanggar']:\n",
        "            solution_parts.append(f\"Pasal: {meta['pasal_yang_dilanggar']}\")\n",
        "\n",
        "        if solution_parts:\n",
        "            return \"; \".join(solution_parts)\n",
        "        else:\n",
        "            return \"Informasi putusan tidak lengkap\"\n",
        "\n",
        "    def extract_all_solutions(self, case_ids: List[str]) -> Dict[str, str]:\n",
        "        \"\"\"\n",
        "        1. Dari kasus top-k, ambil amar putusan atau ringkasan dakwaan\n",
        "        2. Simpan di struktur: {case_id: solusi_text}\n",
        "        \"\"\"\n",
        "        print(f\"\\nüìÑ Extracting solutions for {len(case_ids)} cases...\")\n",
        "\n",
        "        # Load metadata\n",
        "        self.load_case_metadata()\n",
        "\n",
        "        solutions = {}\n",
        "\n",
        "        for case_id in case_ids:\n",
        "            try:\n",
        "                # Strategy 1: Extract from raw text\n",
        "                raw_file = os.path.join(self.raw_dir, f\"{case_id}.txt\")\n",
        "\n",
        "                if os.path.exists(raw_file):\n",
        "                    with open(raw_file, 'r', encoding='utf-8') as f:\n",
        "                        text = f.read()\n",
        "\n",
        "                    solution = self.extract_solution_from_text(text)\n",
        "\n",
        "                    if len(solution.strip()) > 20:  # Valid solution\n",
        "                        solutions[case_id] = solution\n",
        "                        continue\n",
        "\n",
        "                # Strategy 2: Use metadata\n",
        "                solution = self.create_solution_from_metadata(case_id)\n",
        "                solutions[case_id] = solution\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"‚ö†Ô∏è Error extracting solution for {case_id}: {e}\")\n",
        "                solutions[case_id] = \"Solusi tidak dapat diekstrak\"\n",
        "\n",
        "        print(f\"‚úÖ Extracted {len(solutions)} solutions\")\n",
        "\n",
        "        # Show sample solutions\n",
        "        sample_cases = list(solutions.keys())[:3]\n",
        "        for case_id in sample_cases:\n",
        "            solution = solutions[case_id]\n",
        "            short_solution = solution[:100] + \"...\" if len(solution) > 100 else solution\n",
        "            print(f\"   {case_id}: {short_solution}\")\n",
        "\n",
        "        self.case_solutions = solutions\n",
        "        return solutions\n"
      ],
      "metadata": {
        "id": "SZvevTJ4GQFn"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Algoritma Prediksi dan Implementasi Fungsi"
      ],
      "metadata": {
        "id": "CRqcSvzjGfCy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# ii. ALGORITMA PREDIKSI\n",
        "# 1. Majority vote: pilih solusi yang paling banyak muncul\n",
        "# 2. Weighted similarity: bobot = skor similarity\n",
        "# ============================================================================\n",
        "\n",
        "class SolutionPredictor:\n",
        "    \"\"\"\n",
        "    ii. Algoritma Prediksi & iii. Implementasi Fungsi\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, base_dir=\"/content/drive/MyDrive/perdagangan_orang\"):\n",
        "        self.base_dir = base_dir\n",
        "\n",
        "        # Components\n",
        "        self.retrieval_system = RetrievalSystem(base_dir)\n",
        "        self.solution_extractor = SolutionExtractor(base_dir)\n",
        "\n",
        "        # Cache all solutions untuk efisiensi\n",
        "        self._initialize_solution_cache()\n",
        "\n",
        "        print(\"üîÆ ii. ALGORITMA PREDIKSI\")\n",
        "\n",
        "    def _initialize_solution_cache(self):\n",
        "        \"\"\"Initialize cache dengan semua solusi yang tersedia\"\"\"\n",
        "        print(\"üíæ Initializing solution cache...\")\n",
        "\n",
        "        if self.retrieval_system.case_ids:\n",
        "            # Extract solutions untuk semua cases\n",
        "            all_solutions = self.solution_extractor.extract_all_solutions(\n",
        "                self.retrieval_system.case_ids\n",
        "            )\n",
        "            print(f\"‚úÖ Cached {len(all_solutions)} solutions\")\n",
        "\n",
        "    def majority_vote(self, solutions: List[str]) -> str:\n",
        "        \"\"\"\n",
        "        1. Majority vote: pilih solusi yang paling banyak muncul\n",
        "        \"\"\"\n",
        "        if not solutions:\n",
        "            return \"Tidak ada solusi tersedia\"\n",
        "\n",
        "        # Normalisasi solusi untuk counting\n",
        "        normalized_solutions = []\n",
        "        for sol in solutions:\n",
        "            # Ambil kata kunci utama\n",
        "            sol_lower = sol.lower()\n",
        "\n",
        "            # Extract key decision words\n",
        "            key_words = []\n",
        "            if 'terbukti' in sol_lower and 'tidak' not in sol_lower:\n",
        "                key_words.append('terbukti')\n",
        "            elif 'tidak terbukti' in sol_lower:\n",
        "                key_words.append('tidak_terbukti')\n",
        "\n",
        "            if 'penjara' in sol_lower or 'pidana' in sol_lower:\n",
        "                key_words.append('penjara')\n",
        "            if 'denda' in sol_lower:\n",
        "                key_words.append('denda')\n",
        "            if 'bebas' in sol_lower:\n",
        "                key_words.append('bebas')\n",
        "\n",
        "            normalized = '_'.join(key_words) if key_words else 'unknown'\n",
        "            normalized_solutions.append(normalized)\n",
        "\n",
        "        # Count occurrences\n",
        "        counter = Counter(normalized_solutions)\n",
        "        most_common = counter.most_common(1)[0][0]\n",
        "\n",
        "        # Map back to original solution\n",
        "        for i, norm_sol in enumerate(normalized_solutions):\n",
        "            if norm_sol == most_common:\n",
        "                return solutions[i]\n",
        "\n",
        "        return solutions[0]  # Fallback\n",
        "\n",
        "    def weighted_similarity(self, solutions: List[str], scores: List[float]) -> str:\n",
        "        \"\"\"\n",
        "        2. Weighted similarity: bobot = skor similarity\n",
        "        \"\"\"\n",
        "        if not solutions or not scores:\n",
        "            return \"Tidak ada solusi tersedia\"\n",
        "\n",
        "        # Normalisasi scores\n",
        "        total_score = sum(scores)\n",
        "        if total_score == 0:\n",
        "            return self.majority_vote(solutions)\n",
        "\n",
        "        weights = [score / total_score for score in scores]\n",
        "\n",
        "        # Group solutions by similarity\n",
        "        solution_weights = defaultdict(float)\n",
        "        solution_examples = {}\n",
        "\n",
        "        for sol, weight in zip(solutions, weights):\n",
        "            # Simplify solution for grouping\n",
        "            sol_key = self._simplify_solution(sol)\n",
        "            solution_weights[sol_key] += weight\n",
        "            if sol_key not in solution_examples:\n",
        "                solution_examples[sol_key] = sol\n",
        "\n",
        "        # Pilih solusi dengan weight tertinggi\n",
        "        best_solution_key = max(solution_weights, key=solution_weights.get)\n",
        "        return solution_examples[best_solution_key]\n",
        "\n",
        "    def _simplify_solution(self, solution: str) -> str:\n",
        "        \"\"\"Simplify solution untuk grouping\"\"\"\n",
        "        sol_lower = solution.lower()\n",
        "\n",
        "        if 'tidak terbukti' in sol_lower or 'bebas' in sol_lower:\n",
        "            return 'tidak_terbukti'\n",
        "        elif 'terbukti' in sol_lower:\n",
        "            if 'penjara' in sol_lower and 'denda' in sol_lower:\n",
        "                return 'terbukti_penjara_denda'\n",
        "            elif 'penjara' in sol_lower:\n",
        "                return 'terbukti_penjara'\n",
        "            elif 'denda' in sol_lower:\n",
        "                return 'terbukti_denda'\n",
        "            else:\n",
        "                return 'terbukti'\n",
        "        else:\n",
        "                return 'unknown'\n",
        "\n",
        "    def predict_outcome(self, query: str, k: int = 5, method: str = 'weighted') -> Dict:\n",
        "        \"\"\"\n",
        "        Implementasi Fungsi predict_outcome sesuai spesifikasi\n",
        "        \"\"\"\n",
        "        # Retrieve top-k similar cases\n",
        "        if method == 'weighted':\n",
        "            top_cases_with_scores = self.retrieval_system.retrieve_with_scores(query, k=k)\n",
        "            top_k = [case for case, score in top_cases_with_scores]\n",
        "            scores = [score for case, score in top_cases_with_scores]\n",
        "        else:\n",
        "            top_k = self.retrieval_system.retrieve(query, k=k)\n",
        "            scores = [1.0] * len(top_k)  # Equal weights for majority vote\n",
        "\n",
        "        if not top_k:\n",
        "            return {\n",
        "                'predicted_solution': \"Tidak dapat menemukan kasus serupa\",\n",
        "                'top_cases': [],\n",
        "                'method': method,\n",
        "                'confidence': 0.0\n",
        "            }\n",
        "\n",
        "        # Extract solutions from top-k cases\n",
        "        solutions = []\n",
        "        valid_cases = []\n",
        "        valid_scores = []\n",
        "\n",
        "        for i, case_id in enumerate(top_k):\n",
        "            if case_id in self.solution_extractor.case_solutions:\n",
        "                solution = self.solution_extractor.case_solutions[case_id]\n",
        "                solutions.append(solution)\n",
        "                valid_cases.append(case_id)\n",
        "                valid_scores.append(scores[i])\n",
        "\n",
        "        if not solutions:\n",
        "            return {\n",
        "                'predicted_solution': \"Solusi tidak tersedia untuk kasus serupa\",\n",
        "                'top_cases': top_k,\n",
        "                'method': method,\n",
        "                'confidence': 0.0\n",
        "            }\n",
        "\n",
        "        # Apply prediction algorithm\n",
        "        if method == 'majority':\n",
        "            predicted_solution = self.majority_vote(solutions)\n",
        "        else:  # weighted\n",
        "            predicted_solution = self.weighted_similarity(solutions, valid_scores)\n",
        "\n",
        "        # Calculate confidence\n",
        "        confidence = sum(valid_scores) / len(valid_scores) if valid_scores else 0.0\n",
        "\n",
        "        return {\n",
        "            'predicted_solution': predicted_solution,\n",
        "            'top_cases': valid_cases,\n",
        "            'case_solutions': dict(zip(valid_cases, solutions)),\n",
        "            'similarity_scores': valid_scores,\n",
        "            'method': method,\n",
        "            'confidence': confidence,\n",
        "            'query': query\n",
        "        }\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "OfVwltf7GiFb"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Demo Manual"
      ],
      "metadata": {
        "id": "j_JCx7L3Gt5p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# iv. DEMO MANUAL\n",
        "# 1. Siapkan 5 contoh kasus baru ‚Üí jalankan predict_outcome() ‚Üí\n",
        "#    bandingkan dengan putusan sebenarnya\n",
        "# ============================================================================\n",
        "\n",
        "class ManualDemo:\n",
        "    \"\"\"\n",
        "    iv. Demo Manual\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, base_dir=\"/content/drive/MyDrive/perdagangan_orang\"):\n",
        "        self.base_dir = base_dir\n",
        "        self.results_dir = os.path.join(base_dir, \"data\", \"results\")\n",
        "\n",
        "        os.makedirs(self.results_dir, exist_ok=True)\n",
        "\n",
        "        self.predictor = SolutionPredictor(base_dir)\n",
        "\n",
        "        print(\"üß™ iv. DEMO MANUAL\")\n",
        "\n",
        "    def create_demo_cases(self) -> List[Dict]:\n",
        "        \"\"\"\n",
        "        1. Siapkan 5 contoh kasus baru\n",
        "        \"\"\"\n",
        "        demo_cases = [\n",
        "              {\n",
        "              \"query_id\": \"DEMO_001\",\n",
        "              \"query\": \"terdakwa merekrut dan mengirim perempuan ke luar negeri untuk dieksploitasi secara seksual\",\n",
        "              \"expected_outcome\": \"Terbukti bersalah, pidana penjara dan restitusi kepada korban\",\n",
        "              \"description\": \"Eksploitasi seksual lintas negara\"\n",
        "          },\n",
        "          {\n",
        "              \"query_id\": \"DEMO_002\",\n",
        "              \"query\": \"terdakwa memindahkan anak di bawah umur untuk dijadikan pekerja rumah tangga tanpa izin resmi\",\n",
        "              \"expected_outcome\": \"Terbukti bersalah, pidana penjara dan perlindungan korban anak\",\n",
        "              \"description\": \"Eksploitasi anak untuk kerja paksa\"\n",
        "          },\n",
        "          {\n",
        "              \"query_id\": \"DEMO_003\",\n",
        "              \"query\": \"korban dijanjikan pekerjaan lalu dieksploitasi di tempat hiburan malam oleh terdakwa\",\n",
        "              \"expected_outcome\": \"Terbukti bersalah, pidana penjara dan pencabutan izin usaha\",\n",
        "              \"description\": \"Penipuan dan eksploitasi tenaga kerja perempuan\"\n",
        "          },\n",
        "          {\n",
        "              \"query_id\": \"DEMO_004\",\n",
        "              \"query\": \"terdakwa menggunakan agen tenaga kerja ilegal untuk mengirim korban ke Timur Tengah tanpa dokumen sah\",\n",
        "              \"expected_outcome\": \"Terbukti bersalah, pidana penjara dan denda\",\n",
        "              \"description\": \"Perdagangan orang melalui agen tidak resmi\"\n",
        "          },\n",
        "          {\n",
        "              \"query_id\": \"DEMO_005\",\n",
        "              \"query\": \"perempuan muda dipaksa untuk bekerja di luar negeri di bawah ancaman kekerasan dan tanpa upah\",\n",
        "              \"expected_outcome\": \"Terbukti bersalah, pidana penjara dan restitusi kepada korban\",\n",
        "              \"description\": \"Kerja paksa dan ancaman kekerasan\"\n",
        "          }\n",
        "        ]\n",
        "\n",
        "        print(f\"üìù Created {len(demo_cases)} demo cases\")\n",
        "        for case in demo_cases:\n",
        "            print(f\"   {case['query_id']}: {case['description']}\")\n",
        "\n",
        "        return demo_cases\n",
        "\n",
        "    def run_demo(self) -> List[Dict]:\n",
        "        \"\"\"\n",
        "        2. Jalankan predict_outcome() untuk setiap kasus demo\n",
        "        \"\"\"\n",
        "        demo_cases = self.create_demo_cases()\n",
        "        results = []\n",
        "\n",
        "        print(f\"\\nüîÆ Running prediction demo...\")\n",
        "\n",
        "        for case in demo_cases:\n",
        "            query_id = case['query_id']\n",
        "            query = case['query']\n",
        "            expected = case['expected_outcome']\n",
        "\n",
        "            print(f\"\\n--- {query_id} ---\")\n",
        "            print(f\"Query: {query}\")\n",
        "            print(f\"Expected: {expected}\")\n",
        "\n",
        "            # Test both methods\n",
        "            for method in ['weighted', 'majority']:\n",
        "                try:\n",
        "                    prediction_result = self.predictor.predict_outcome(\n",
        "                        query=query,\n",
        "                        k=5,\n",
        "                        method=method\n",
        "                    )\n",
        "\n",
        "                    predicted_solution = prediction_result['predicted_solution']\n",
        "                    confidence = prediction_result['confidence']\n",
        "                    top_cases = prediction_result['top_cases']\n",
        "\n",
        "                    print(f\"\\n{method.upper()} Method:\")\n",
        "                    print(f\"  Predicted: {predicted_solution[:100]}...\")\n",
        "                    print(f\"  Confidence: {confidence:.3f}\")\n",
        "                    print(f\"  Top cases: {top_cases[:3]}\")\n",
        "\n",
        "                    # Compare with expected\n",
        "                    comparison = self.compare_prediction(predicted_solution, expected)\n",
        "                    print(f\"  Match score: {comparison['score']:.2f}\")\n",
        "\n",
        "                    result = {\n",
        "                        'query_id': query_id,\n",
        "                        'query': query,\n",
        "                        'method': method,\n",
        "                        'predicted_solution': predicted_solution,\n",
        "                        'expected_outcome': expected,\n",
        "                        'confidence': confidence,\n",
        "                        'top_cases': top_cases,\n",
        "                        'match_score': comparison['score'],\n",
        "                        'match_explanation': comparison['explanation']\n",
        "                    }\n",
        "\n",
        "                    results.append(result)\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"  ‚ùå Error: {e}\")\n",
        "\n",
        "                    error_result = {\n",
        "                        'query_id': query_id,\n",
        "                        'query': query,\n",
        "                        'method': method,\n",
        "                        'predicted_solution': f\"Error: {str(e)}\",\n",
        "                        'expected_outcome': expected,\n",
        "                        'confidence': 0.0,\n",
        "                        'top_cases': [],\n",
        "                        'match_score': 0.0,\n",
        "                        'match_explanation': 'Prediction failed'\n",
        "                    }\n",
        "\n",
        "                    results.append(error_result)\n",
        "\n",
        "        return results\n",
        "\n",
        "    def compare_prediction(self, predicted: str, expected: str) -> Dict:\n",
        "        \"\"\"\n",
        "        3. Bandingkan dengan putusan sebenarnya\n",
        "        \"\"\"\n",
        "        pred_lower = predicted.lower()\n",
        "        exp_lower = expected.lower()\n",
        "\n",
        "        score = 0.0\n",
        "        explanations = []\n",
        "\n",
        "        # Check for key terms\n",
        "        key_terms = [\n",
        "            ('terbukti', 0.3),\n",
        "            ('tidak terbukti', 0.3),\n",
        "            ('penjara', 0.2),\n",
        "            ('pidana', 0.2),\n",
        "            ('denda', 0.15),\n",
        "            ('bebas', 0.2)\n",
        "        ]\n",
        "\n",
        "        for term, weight in key_terms:\n",
        "            if term in pred_lower and term in exp_lower:\n",
        "                score += weight\n",
        "                explanations.append(f\"‚úÖ Found '{term}'\")\n",
        "            elif term in exp_lower and term not in pred_lower:\n",
        "                explanations.append(f\"‚ùå Missing '{term}'\")\n",
        "            elif term in pred_lower and term not in exp_lower:\n",
        "                explanations.append(f\"‚ö†Ô∏è Extra '{term}'\")\n",
        "\n",
        "        # Bonus for overall direction match\n",
        "        if ('terbukti' in pred_lower and 'terbukti' in exp_lower) or \\\n",
        "           ('tidak terbukti' in pred_lower and ('tidak terbukti' in exp_lower or 'bebas' in exp_lower)):\n",
        "            score += 0.2\n",
        "            explanations.append(\"‚úÖ Overall direction matches\")\n",
        "\n",
        "        score = min(score, 1.0)  # Cap at 1.0\n",
        "\n",
        "        return {\n",
        "            'score': score,\n",
        "            'explanation': '; '.join(explanations)\n",
        "        }"
      ],
      "metadata": {
        "id": "KF6T0fyJGrJo"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# v. OUTPUT\n",
        "# 1. Script 04_predict.py / notebook\n",
        "# 2. File /data/results/predictions.csv berisi:\n",
        "#    query_id predicted_solution top_5_case_ids\n",
        "# ============================================================================\n",
        "\n",
        "class OutputGenerator:\n",
        "    \"\"\"\n",
        "    v. Output\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, base_dir=\"/content/drive/MyDrive/perdagangan_orang\"):\n",
        "        self.base_dir = base_dir\n",
        "        self.results_dir = os.path.join(base_dir, \"data\", \"results\")\n",
        "\n",
        "        os.makedirs(self.results_dir, exist_ok=True)\n",
        "\n",
        "        print(\"üìä v. OUTPUT\")\n",
        "\n",
        "    def save_predictions_csv(self, results: List[Dict]) -> str:\n",
        "        \"\"\"\n",
        "        2. File /data/results/predictions.csv berisi:\n",
        "           query_id predicted_solution top_5_case_ids\n",
        "        \"\"\"\n",
        "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "        csv_filename = f\"predictions_{timestamp}.csv\"\n",
        "        csv_path = os.path.join(self.results_dir, csv_filename)\n",
        "\n",
        "        # Prepare data for CSV\n",
        "        csv_data = []\n",
        "\n",
        "        for result in results:\n",
        "            # Convert top_cases list to string\n",
        "            top_5_case_ids = ';'.join(result['top_cases'][:5])\n",
        "\n",
        "            csv_row = {\n",
        "                'query_id': result['query_id'],\n",
        "                'query': result['query'],\n",
        "                'method': result['method'],\n",
        "                'predicted_solution': result['predicted_solution'],\n",
        "                'expected_outcome': result['expected_outcome'],\n",
        "                'top_5_case_ids': top_5_case_ids,\n",
        "                'confidence': result['confidence'],\n",
        "                'match_score': result['match_score'],\n",
        "                'match_explanation': result['match_explanation']\n",
        "            }\n",
        "\n",
        "            csv_data.append(csv_row)\n",
        "\n",
        "        # Save to CSV\n",
        "        df = pd.DataFrame(csv_data)\n",
        "        df.to_csv(csv_path, index=False, encoding='utf-8')\n",
        "\n",
        "        print(f\"üìÑ Predictions saved: {csv_filename}\")\n",
        "        print(f\"   Records: {len(csv_data)}\")\n",
        "        print(f\"   Columns: {list(df.columns)}\")\n",
        "\n",
        "        return csv_path\n",
        "\n",
        "    def save_detailed_results(self, results: List[Dict]) -> str:\n",
        "        \"\"\"Save detailed results as JSON\"\"\"\n",
        "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "        json_filename = f\"detailed_predictions_{timestamp}.json\"\n",
        "        json_path = os.path.join(self.results_dir, json_filename)\n",
        "\n",
        "        detailed_data = {\n",
        "            'metadata': {\n",
        "                'generated_at': datetime.now().isoformat(),\n",
        "                'total_predictions': len(results),\n",
        "                'methods_used': list(set([r['method'] for r in results])),\n",
        "                'version': 'solution_reuse_v1'\n",
        "            },\n",
        "            'results': results\n",
        "        }\n",
        "\n",
        "        with open(json_path, 'w', encoding='utf-8') as f:\n",
        "            json.dump(detailed_data, f, ensure_ascii=False, indent=2, default=str)\n",
        "\n",
        "        print(f\"üìÑ Detailed results saved: {json_filename}\")\n",
        "\n",
        "        return json_path\n",
        "\n",
        "    def generate_summary_report(self, results: List[Dict]) -> str:\n",
        "        \"\"\"Generate summary report\"\"\"\n",
        "        report = []\n",
        "        report.append(\"=\" * 70)\n",
        "        report.append(\"üîÆ TAHAP 4 - SOLUTION REUSE - SUMMARY REPORT\")\n",
        "        report.append(\"=\" * 70)\n",
        "        report.append(f\"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "        report.append(\"\")\n",
        "\n",
        "        # Overall statistics\n",
        "        total_predictions = len(results)\n",
        "        successful_predictions = len([r for r in results if 'Error' not in r['predicted_solution']])\n",
        "        avg_confidence = np.mean([r['confidence'] for r in results if r['confidence'] > 0])\n",
        "        avg_match_score = np.mean([r['match_score'] for r in results])\n",
        "\n",
        "        report.append(\"üìä OVERALL STATISTICS:\")\n",
        "        report.append(f\"  Total predictions: {total_predictions}\")\n",
        "        report.append(f\"  Successful predictions: {successful_predictions} ({successful_predictions/total_predictions*100:.1f}%)\")\n",
        "        report.append(f\"  Average confidence: {avg_confidence:.3f}\")\n",
        "        report.append(f\"  Average match score: {avg_match_score:.3f}\")\n",
        "        report.append(\"\")\n",
        "\n",
        "        # Method comparison\n",
        "        methods = list(set([r['method'] for r in results]))\n",
        "        report.append(\"üîß METHOD COMPARISON:\")\n",
        "\n",
        "        for method in methods:\n",
        "            method_results = [r for r in results if r['method'] == method]\n",
        "            method_confidence = np.mean([r['confidence'] for r in method_results if r['confidence'] > 0])\n",
        "            method_match = np.mean([r['match_score'] for r in method_results])\n",
        "\n",
        "            report.append(f\"  {method.upper()}:\")\n",
        "            report.append(f\"    Avg Confidence: {method_confidence:.3f}\")\n",
        "            report.append(f\"    Avg Match Score: {method_match:.3f}\")\n",
        "\n",
        "        report.append(\"\")\n",
        "\n",
        "        # Best predictions\n",
        "        report.append(\"üèÜ BEST PREDICTIONS:\")\n",
        "        best_results = sorted([r for r in results if r['match_score'] > 0],\n",
        "                             key=lambda x: x['match_score'], reverse=True)[:3]\n",
        "\n",
        "        for i, result in enumerate(best_results, 1):\n",
        "            report.append(f\"  {i}. {result['query_id']} ({result['method']})\")\n",
        "            report.append(f\"     Query: {result['query'][:50]}...\")\n",
        "            report.append(f\"     Match Score: {result['match_score']:.3f}\")\n",
        "            report.append(f\"     Confidence: {result['confidence']:.3f}\")\n",
        "\n",
        "        report.append(\"\")\n",
        "\n",
        "        # Performance assessment\n",
        "        if avg_match_score >= 0.7:\n",
        "            report.append(\"üéâ EXCELLENT: System performing very well!\")\n",
        "        elif avg_match_score >= 0.5:\n",
        "            report.append(\"‚úÖ GOOD: System performing adequately\")\n",
        "        elif avg_match_score >= 0.3:\n",
        "            report.append(\"‚ö†Ô∏è FAIR: System needs improvement\")\n",
        "        else:\n",
        "            report.append(\"‚ùå POOR: System requires significant work\")\n",
        "\n",
        "        report.append(\"=\" * 70)\n",
        "\n",
        "        return \"\\n\".join(report)\n",
        "\n",
        "class SolutionReuseSystem:\n",
        "    \"\"\"\n",
        "    Main class untuk Tahap 4 - Solution Reuse\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, base_dir=\"/content/drive/MyDrive/perdagangan_orang\"):\n",
        "        self.base_dir = base_dir\n",
        "\n",
        "        print(\"üîÆ TAHAP 4 - SOLUTION REUSE\")\n",
        "        print(\"=\" * 60)\n",
        "        print(\"Tujuan: Gunakan putusan lama sebagai dasar pencarian untuk kasus baru\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        # Initialize components\n",
        "        self.solution_extractor = SolutionExtractor(base_dir)\n",
        "        self.predictor = SolutionPredictor(base_dir)\n",
        "        self.demo = ManualDemo(base_dir)\n",
        "        self.output_generator = OutputGenerator(base_dir)\n",
        "\n",
        "    def run_complete_solution_reuse(self) -> bool:\n",
        "        \"\"\"\n",
        "        Jalankan semua tahap solution reuse\n",
        "        \"\"\"\n",
        "        try:\n",
        "            print(\"\\nüîÆ Running complete solution reuse process...\")\n",
        "\n",
        "            # iv. Demo Manual\n",
        "            print(\"\\n\" + \"=\"*50)\n",
        "            print(\"üß™ iv. DEMO MANUAL\")\n",
        "            print(\"=\"*50)\n",
        "\n",
        "            demo_results = self.demo.run_demo()\n",
        "\n",
        "            if not demo_results:\n",
        "                print(\"‚ùå Demo failed - no results generated\")\n",
        "                return False\n",
        "\n",
        "            # v. Output\n",
        "            print(\"\\n\" + \"=\"*50)\n",
        "            print(\"üìä v. OUTPUT\")\n",
        "            print(\"=\"*50)\n",
        "\n",
        "            # Save CSV\n",
        "            csv_path = self.output_generator.save_predictions_csv(demo_results)\n",
        "\n",
        "            # Save detailed JSON\n",
        "            json_path = self.output_generator.save_detailed_results(demo_results)\n",
        "\n",
        "            # Generate and show report\n",
        "            report = self.output_generator.generate_summary_report(demo_results)\n",
        "            print(f\"\\n{report}\")\n",
        "\n",
        "            # Final success message\n",
        "            print(\"\\n\" + \"=\" * 60)\n",
        "            print(\"‚úÖ TAHAP 4 - SOLUTION REUSE COMPLETED!\")\n",
        "            print(\"üìÅ Output files created:\")\n",
        "            print(f\"   - {os.path.basename(csv_path)}\")\n",
        "            print(f\"   - {os.path.basename(json_path)}\")\n",
        "            print(\"üîÆ Solution reuse system ready for production!\")\n",
        "            print(\"=\" * 60)\n",
        "\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error in solution reuse process: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "            return False\n",
        "\n",
        "def test_individual_components():\n",
        "    \"\"\"Test individual components untuk debugging\"\"\"\n",
        "    print(\"üß™ TESTING INDIVIDUAL COMPONENTS\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    base_dir = \"/content/drive/MyDrive/perdagangan_orang\"\n",
        "\n",
        "    # Test 1: Retrieval System\n",
        "    print(\"\\n1. Testing Retrieval System...\")\n",
        "    try:\n",
        "        retrieval = RetrievalSystem(base_dir)\n",
        "        if retrieval.case_ids:\n",
        "            test_queries = [\n",
        "                \"perdagangan orang lintas negara\",\n",
        "                \"eksploitasi tenaga kerja wanita\",\n",
        "                \"anak dijual untuk prostitusi\",\n",
        "                \"pemaksaan kerja paksa perdagangan orang\"\n",
        "            ]\n",
        "            results = retrieval.retrieve(test_query, k=3)\n",
        "            print(f\"‚úÖ Retrieval working: {len(results)} results for '{test_query}'\")\n",
        "        else:\n",
        "            print(\"‚ùå Retrieval system has no cases\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Retrieval test failed: {e}\")\n",
        "\n",
        "    # Test 2: Solution Extractor\n",
        "    print(\"\\n2. Testing Solution Extractor...\")\n",
        "    try:\n",
        "        extractor = SolutionExtractor(base_dir)\n",
        "        if extractor.load_case_metadata():\n",
        "            sample_cases = list(extractor.case_metadata.keys())[:3]\n",
        "            solutions = extractor.extract_all_solutions(sample_cases)\n",
        "            print(f\"‚úÖ Extraction working: {len(solutions)} solutions extracted\")\n",
        "        else:\n",
        "            print(\"‚ùå Cannot load case metadata\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Extraction test failed: {e}\")\n",
        "\n",
        "    # Test 3: Predictor\n",
        "    print(\"\\n3. Testing Predictor...\")\n",
        "    try:\n",
        "        predictor = SolutionPredictor(base_dir)\n",
        "        test_query = \"penyuapan pejabat\"\n",
        "        result = predictor.predict_outcome(test_query, k=3)\n",
        "        print(f\"‚úÖ Prediction working: '{result['predicted_solution'][:50]}...'\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Prediction test failed: {e}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 50)\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Fungsi utama untuk Tahap 4 - Solution Reuse\n",
        "    \"\"\"\n",
        "    print(\"üöÄ MULAI TAHAP 4 - SOLUTION REUSE\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    try:\n",
        "        # Optional: Test individual components first\n",
        "        # test_individual_components()\n",
        "\n",
        "        # Run complete solution reuse system\n",
        "        system = SolutionReuseSystem()\n",
        "        success = system.run_complete_solution_reuse()\n",
        "\n",
        "        if success:\n",
        "            print(f\"\\nüéâ TAHAP 4 BERHASIL!\")\n",
        "            print(\"‚ú® Yang telah diselesaikan:\")\n",
        "            print(\"  ‚úÖ i. Ekstrak Solusi dari kasus top-k\")\n",
        "            print(\"  ‚úÖ ii. Algoritma Prediksi (majority vote & weighted similarity)\")\n",
        "            print(\"  ‚úÖ iii. Implementasi Fungsi predict_outcome()\")\n",
        "            print(\"  ‚úÖ iv. Demo Manual dengan 5 contoh kasus\")\n",
        "            print(\"  ‚úÖ v. Output CSV dan JSON hasil prediksi\")\n",
        "            print(\"üîÆ Solution reuse system siap digunakan!\")\n",
        "        else:\n",
        "            print(\"\\n‚ùå Tahap 4 gagal diselesaikan\")\n",
        "            print(\"üîß Jalankan test_individual_components() untuk debugging\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nüí• ERROR: {str(e)}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n",
        "# ============================================================================\n",
        "# ADDITIONAL UTILITY FUNCTIONS\n",
        "# ============================================================================\n",
        "\n",
        "def quick_predict(query: str, base_dir=\"/content/drive/MyDrive/perdagangan_orang\") -> str:\n",
        "    \"\"\"\n",
        "    Fungsi prediksi cepat satu query (untuk TPPO)\n",
        "\n",
        "    Usage:\n",
        "    result = quick_predict(\"perdagangan orang lintas negara\")\n",
        "    print(result)\n",
        "    \"\"\"\n",
        "    try:\n",
        "        predictor = SolutionPredictor(base_dir)\n",
        "        result = predictor.predict_outcome(query, k=5, method='weighted')\n",
        "        return result['predicted_solution']\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\"\n",
        "\n",
        "def batch_predict(queries: List[str], base_dir=\"/content/drive/MyDrive/perdagangan_orang\") -> List[Dict]:\n",
        "    \"\"\"\n",
        "    Fungsi prediksi batch untuk banyak query (topik TPPO)\n",
        "\n",
        "    Usage:\n",
        "    queries = [\n",
        "        \"perdagangan orang lintas negara\",\n",
        "        \"eksploitasi anak untuk prostitusi\",\n",
        "        \"kerja paksa terhadap wanita migran\"\n",
        "    ]\n",
        "    results = batch_predict(queries)\n",
        "    for r in results:\n",
        "        print(r)\n",
        "    \"\"\"\n",
        "    predictor = SolutionPredictor(base_dir)\n",
        "    results = []\n",
        "\n",
        "    for i, query in enumerate(queries):\n",
        "        try:\n",
        "            result = predictor.predict_outcome(query, k=5, method='weighted')\n",
        "            result['query_id'] = f\"BATCH_{i+1:03d}\"\n",
        "            results.append(result)\n",
        "        except Exception as e:\n",
        "            error_result = {\n",
        "                'query_id': f\"BATCH_{i+1:03d}\",\n",
        "                'query': query,\n",
        "                'predicted_solution': f\"Error: {str(e)}\",\n",
        "                'confidence': 0.0,\n",
        "                'top_cases': []\n",
        "            }\n",
        "            results.append(error_result)\n",
        "\n",
        "    return results\n",
        "\n",
        "def interactive_demo(base_dir=\"/content/drive/MyDrive/perdagangan_orang\"):\n",
        "    \"\"\"\n",
        "    Interactive demo untuk testing manual\n",
        "    \"\"\"\n",
        "    print(\"üîÆ INTERACTIVE SOLUTION REUSE DEMO\")\n",
        "    print(\"=\" * 50)\n",
        "    print(\"Masukkan query kasus hukum (atau 'quit' untuk keluar)\")\n",
        "\n",
        "    predictor = SolutionPredictor(base_dir)\n",
        "\n",
        "    while True:\n",
        "        query = input(\"\\nüîç Query: \").strip()\n",
        "\n",
        "        if query.lower() in ['quit', 'exit', 'q']:\n",
        "            break\n",
        "\n",
        "        if not query:\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            print(f\"üîÆ Predicting for: '{query}'\")\n",
        "\n",
        "            # Test both methods\n",
        "            for method in ['weighted', 'majority']:\n",
        "                result = predictor.predict_outcome(query, k=5, method=method)\n",
        "\n",
        "                print(f\"\\n{method.upper()} METHOD:\")\n",
        "                print(f\"Prediction: {result['predicted_solution']}\")\n",
        "                print(f\"Confidence: {result['confidence']:.3f}\")\n",
        "                print(f\"Top cases: {result['top_cases'][:3]}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error: {e}\")\n",
        "\n",
        "    print(\"üëã Demo selesai!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kaJA5sW9Hl0A",
        "outputId": "c61477be-d3de-4a61-b915-867b117ad16c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ MULAI TAHAP 4 - SOLUTION REUSE\n",
            "======================================================================\n",
            "üîÆ TAHAP 4 - SOLUTION REUSE\n",
            "============================================================\n",
            "Tujuan: Gunakan putusan lama sebagai dasar pencarian untuk kasus baru\n",
            "============================================================\n",
            "üìÑ i. EKSTRAK SOLUSI\n",
            "üîç Loading retrieval components...\n",
            "‚úÖ Loaded: 79 cases, 4,489 vocab\n",
            "üìÑ i. EKSTRAK SOLUSI\n",
            "üíæ Initializing solution cache...\n",
            "\n",
            "üìÑ Extracting solutions for 79 cases...\n",
            "‚úÖ Loaded metadata for 79 cases\n",
            "‚úÖ Extracted 79 solutions\n",
            "   case_2021_TK1_Putusan_PT_MATARAM_Nomor_145_PID_SUS_2021_PT_MTR_Tanggal_20_Desember_2021__Pembanding_Penuntut_Umum___MANIK_ARTHA_ADHITAMA__SHTerbanding_Terdakwa___Herman_Saputra_Rafiudin_Alias_Herman: mengadili perkara-perkara pidana pada tingkat banding, telah menjatuhkan putusan sebagai berikut dal...\n",
            "   case_2021_TK1_Putusan_PN_PELAIHARI_Nomor_179_Pid_Sus_2021_PN_Pli_Tanggal_16_Desember_2021__Penuntut_Umum_ANDI_HAMZAH_KUSUMAATMAJA__S_HTerdakwa_M__NOOR_Als_NUNUI_Bin_KHAIRI: amar putusan ini;memperhatikan, pasal 296 kitab undang-undang hukum pidana,undang-undang nomor 8 tah...\n",
            "   case_2021_TK1_Putusan_PT_MATARAM_Nomor_140_PID_SUS_2021_PT_MTR_Tanggal_9_Desember_2021__Pembanding_Penuntut_Umum_I___HENDRO_S_I_B__SH_Terbanding_Terdakwa___BQ_DIAN_CINDRAWATI_Alias_DIAN: mengadili perkara-perkara pidana dalam tingkat banding menjatuhkan putusan sebagai berikutdalam perk...\n",
            "‚úÖ Cached 79 solutions\n",
            "üîÆ ii. ALGORITMA PREDIKSI\n",
            "üîç Loading retrieval components...\n",
            "‚úÖ Loaded: 79 cases, 4,489 vocab\n",
            "üìÑ i. EKSTRAK SOLUSI\n",
            "üíæ Initializing solution cache...\n",
            "\n",
            "üìÑ Extracting solutions for 79 cases...\n",
            "‚úÖ Loaded metadata for 79 cases\n",
            "‚úÖ Extracted 79 solutions\n",
            "   case_2021_TK1_Putusan_PT_MATARAM_Nomor_145_PID_SUS_2021_PT_MTR_Tanggal_20_Desember_2021__Pembanding_Penuntut_Umum___MANIK_ARTHA_ADHITAMA__SHTerbanding_Terdakwa___Herman_Saputra_Rafiudin_Alias_Herman: mengadili perkara-perkara pidana pada tingkat banding, telah menjatuhkan putusan sebagai berikut dal...\n",
            "   case_2021_TK1_Putusan_PN_PELAIHARI_Nomor_179_Pid_Sus_2021_PN_Pli_Tanggal_16_Desember_2021__Penuntut_Umum_ANDI_HAMZAH_KUSUMAATMAJA__S_HTerdakwa_M__NOOR_Als_NUNUI_Bin_KHAIRI: amar putusan ini;memperhatikan, pasal 296 kitab undang-undang hukum pidana,undang-undang nomor 8 tah...\n",
            "   case_2021_TK1_Putusan_PT_MATARAM_Nomor_140_PID_SUS_2021_PT_MTR_Tanggal_9_Desember_2021__Pembanding_Penuntut_Umum_I___HENDRO_S_I_B__SH_Terbanding_Terdakwa___BQ_DIAN_CINDRAWATI_Alias_DIAN: mengadili perkara-perkara pidana dalam tingkat banding menjatuhkan putusan sebagai berikutdalam perk...\n",
            "‚úÖ Cached 79 solutions\n",
            "üîÆ ii. ALGORITMA PREDIKSI\n",
            "üß™ iv. DEMO MANUAL\n",
            "üìä v. OUTPUT\n",
            "\n",
            "üîÆ Running complete solution reuse process...\n",
            "\n",
            "==================================================\n",
            "üß™ iv. DEMO MANUAL\n",
            "==================================================\n",
            "üìù Created 5 demo cases\n",
            "   DEMO_001: Eksploitasi seksual lintas negara\n",
            "   DEMO_002: Eksploitasi anak untuk kerja paksa\n",
            "   DEMO_003: Penipuan dan eksploitasi tenaga kerja perempuan\n",
            "   DEMO_004: Perdagangan orang melalui agen tidak resmi\n",
            "   DEMO_005: Kerja paksa dan ancaman kekerasan\n",
            "\n",
            "üîÆ Running prediction demo...\n",
            "\n",
            "--- DEMO_001 ---\n",
            "Query: terdakwa merekrut dan mengirim perempuan ke luar negeri untuk dieksploitasi secara seksual\n",
            "Expected: Terbukti bersalah, pidana penjara dan restitusi kepada korban\n",
            "\n",
            "WEIGHTED Method:\n",
            "  Predicted: amar putusan dibawah ini; menimbang, bahwa oleh karena terdakwa telah dilakukan upaya paksa maka ter...\n",
            "  Confidence: 0.097\n",
            "  Top cases: ['case_2021_TK1_Putusan_PN_PANGKALAN_BUN_Nomor_57_Pid_Sus_2021_PN_Pbu_Tanggal_7_April_2021__Penuntut_Umum_1_GOMGOMAN_H_SIMBOLON__S_H___M_H_2_GANES_ADI_KUSUMA__S_H_Terdakwa_RINDA_EVANNA_HOTMAULI_SIAIAHAAN', 'case_2021_TK1_Putusan_PN_KUALA_SIMPANG_Nomor_23_Pid_Sus_2021_PN_Ksp_Tanggal_8_Maret_2021__Penuntut_Umum_MARIONO__SH_MHTerdakwa_2_SUPRAYETNI_Binti_Alm_KASIMIN3_RAZALI_Bin_alm_SULAIMAN4_ROSMINI_BinTUBARA', 'case_2021_TK1_Putusan_PT_SAMARINDA_Nomor_240_PID_2021_PT_SMR_Tanggal_26_Nopember_2021__Pembanding_Terbanding_Terdakwa___DEVITA_ARIYANI_Als_DORA_Binti_MUSTOPA_Diwakili_Oleh___Nunung_Tri_Sulistiawa__S_H_']\n",
            "  Match score: 0.20\n",
            "\n",
            "MAJORITY Method:\n",
            "  Predicted: amar putusan dibawah ini; menimbang, bahwa oleh karena terdakwa telah dilakukan upaya paksa maka ter...\n",
            "  Confidence: 1.000\n",
            "  Top cases: ['case_2021_TK1_Putusan_PN_PANGKALAN_BUN_Nomor_57_Pid_Sus_2021_PN_Pbu_Tanggal_7_April_2021__Penuntut_Umum_1_GOMGOMAN_H_SIMBOLON__S_H___M_H_2_GANES_ADI_KUSUMA__S_H_Terdakwa_RINDA_EVANNA_HOTMAULI_SIAIAHAAN', 'case_2021_TK1_Putusan_PN_KUALA_SIMPANG_Nomor_23_Pid_Sus_2021_PN_Ksp_Tanggal_8_Maret_2021__Penuntut_Umum_MARIONO__SH_MHTerdakwa_2_SUPRAYETNI_Binti_Alm_KASIMIN3_RAZALI_Bin_alm_SULAIMAN4_ROSMINI_BinTUBARA', 'case_2021_TK1_Putusan_PT_SAMARINDA_Nomor_240_PID_2021_PT_SMR_Tanggal_26_Nopember_2021__Pembanding_Terbanding_Terdakwa___DEVITA_ARIYANI_Als_DORA_Binti_MUSTOPA_Diwakili_Oleh___Nunung_Tri_Sulistiawa__S_H_']\n",
            "  Match score: 0.20\n",
            "\n",
            "--- DEMO_002 ---\n",
            "Query: terdakwa memindahkan anak di bawah umur untuk dijadikan pekerja rumah tangga tanpa izin resmi\n",
            "Expected: Terbukti bersalah, pidana penjara dan perlindungan korban anak\n",
            "\n",
            "WEIGHTED Method:\n",
            "  Predicted: amar putusan nomor 412/pid.sus/2021/pn bpp direktori putusan putusan.mahkamahagung.go.id kepaniteraa...\n",
            "  Confidence: 0.109\n",
            "  Top cases: ['case_2021_TK1_Putusan_PN_BALIKPAPAN_Nomor_412_Pid_Sus_2021_PN_Bpp_Tanggal_30_Nopember_2021__Penuntut_Umum_Ita_Wahyuning_Lestari__SH_Terdakwa_JEKSON_RAJAGUKGUK_Alias_JECO_Anak_dari_ALBERT_RAJAGUKGUK', 'case_2021_TK1_Putusan_PN_Ngabang_Nomor_64_Pid_Sus_2021_PN_Nba_Tanggal_30_Agustus_2021__Penuntut_Umum_Pewira_Saputra_SHTerdakwa_Susanti_Alias_Aling_Anak_Dari_Siau_Ket_Loy', 'case_2021_TK1_Putusan_PN_PANGKALAN_BUN_Nomor_57_Pid_Sus_2021_PN_Pbu_Tanggal_7_April_2021__Penuntut_Umum_1_GOMGOMAN_H_SIMBOLON__S_H___M_H_2_GANES_ADI_KUSUMA__S_H_Terdakwa_RINDA_EVANNA_HOTMAULI_SIAIAHAAN']\n",
            "  Match score: 0.00\n",
            "\n",
            "MAJORITY Method:\n",
            "  Predicted: amar putusan dibawah ini;menimbang, bahwa dalam tuntutan pidananya, penuntut umum jugamemohon agar t...\n",
            "  Confidence: 1.000\n",
            "  Top cases: ['case_2021_TK1_Putusan_PN_BALIKPAPAN_Nomor_412_Pid_Sus_2021_PN_Bpp_Tanggal_30_Nopember_2021__Penuntut_Umum_Ita_Wahyuning_Lestari__SH_Terdakwa_JEKSON_RAJAGUKGUK_Alias_JECO_Anak_dari_ALBERT_RAJAGUKGUK', 'case_2021_TK1_Putusan_PN_Ngabang_Nomor_64_Pid_Sus_2021_PN_Nba_Tanggal_30_Agustus_2021__Penuntut_Umum_Pewira_Saputra_SHTerdakwa_Susanti_Alias_Aling_Anak_Dari_Siau_Ket_Loy', 'case_2021_TK1_Putusan_PN_PANGKALAN_BUN_Nomor_57_Pid_Sus_2021_PN_Pbu_Tanggal_7_April_2021__Penuntut_Umum_1_GOMGOMAN_H_SIMBOLON__S_H___M_H_2_GANES_ADI_KUSUMA__S_H_Terdakwa_RINDA_EVANNA_HOTMAULI_SIAIAHAAN']\n",
            "  Match score: 0.20\n",
            "\n",
            "--- DEMO_003 ---\n",
            "Query: korban dijanjikan pekerjaan lalu dieksploitasi di tempat hiburan malam oleh terdakwa\n",
            "Expected: Terbukti bersalah, pidana penjara dan pencabutan izin usaha\n",
            "\n",
            "WEIGHTED Method:\n",
            "  Predicted: mengadili perkara pidana dengan acara pemeriksaan biasa dalam tingkat pertama menjatuhkan putusan se...\n",
            "  Confidence: 0.090\n",
            "  Top cases: ['case_2021_TK1_Putusan_PN_TANGERANG_Nomor_1614_Pid_Sus_2021_PN_Tng_Tanggal_3_Nopember_2021__Penuntut_Umum_HADI_WIDODO__SHTerdakwa_1_SUBUR_RAHARJO_Bin_SUGITO2_AMAR_SAHIDIN_Als_ABANG_Bin_WARSITO', 'case_2021_TK1_Putusan_PT_SAMARINDA_Nomor_240_PID_2021_PT_SMR_Tanggal_26_Nopember_2021__Pembanding_Terbanding_Terdakwa___DEVITA_ARIYANI_Als_DORA_Binti_MUSTOPA_Diwakili_Oleh___Nunung_Tri_Sulistiawa__S_H_', 'case_2021_TK1_Putusan_PN_KUALA_SIMPANG_Nomor_23_Pid_Sus_2021_PN_Ksp_Tanggal_8_Maret_2021__Penuntut_Umum_MARIONO__SH_MHTerdakwa_2_SUPRAYETNI_Binti_Alm_KASIMIN3_RAZALI_Bin_alm_SULAIMAN4_ROSMINI_BinTUBARA']\n",
            "  Match score: 0.20\n",
            "\n",
            "MAJORITY Method:\n",
            "  Predicted: mengadili perkara pidana dengan acara pemeriksaan biasa dalam tingkat pertama menjatuhkan putusan se...\n",
            "  Confidence: 1.000\n",
            "  Top cases: ['case_2021_TK1_Putusan_PN_TANGERANG_Nomor_1614_Pid_Sus_2021_PN_Tng_Tanggal_3_Nopember_2021__Penuntut_Umum_HADI_WIDODO__SHTerdakwa_1_SUBUR_RAHARJO_Bin_SUGITO2_AMAR_SAHIDIN_Als_ABANG_Bin_WARSITO', 'case_2021_TK1_Putusan_PT_SAMARINDA_Nomor_240_PID_2021_PT_SMR_Tanggal_26_Nopember_2021__Pembanding_Terbanding_Terdakwa___DEVITA_ARIYANI_Als_DORA_Binti_MUSTOPA_Diwakili_Oleh___Nunung_Tri_Sulistiawa__S_H_', 'case_2021_TK1_Putusan_PN_KUALA_SIMPANG_Nomor_23_Pid_Sus_2021_PN_Ksp_Tanggal_8_Maret_2021__Penuntut_Umum_MARIONO__SH_MHTerdakwa_2_SUPRAYETNI_Binti_Alm_KASIMIN3_RAZALI_Bin_alm_SULAIMAN4_ROSMINI_BinTUBARA']\n",
            "  Match score: 0.20\n",
            "\n",
            "--- DEMO_004 ---\n",
            "Query: terdakwa menggunakan agen tenaga kerja ilegal untuk mengirim korban ke Timur Tengah tanpa dokumen sah\n",
            "Expected: Terbukti bersalah, pidana penjara dan denda\n",
            "\n",
            "WEIGHTED Method:\n",
            "  Predicted: mengadili perkara-perkara pidana dalam tingkat banding, telah menjatuhkan putusan seperttersebut dib...\n",
            "  Confidence: 0.062\n",
            "  Top cases: ['case_2021_TK1_Putusan_PT_MATARAM_Nomor_120_PID_SUS_2021_PT_MTR_Tanggal_8_Nopember_2021__Pembanding_Terbanding_Terdakwa___RATNI__SH_Alias_RANITerbanding_Pembanding_Penuntut_Umum___FEDDY_HANTYO_NUG__M_H_', 'case_2021_TK1_Putusan_PT_PADANG_Nomor_70_PID_SUS_2021_PT_PDG_Tanggal_27_April_2021__Pembanding_Penuntut_Umum_I___MEILYA_TRISNA__SH__MHTerbanding_Terdakwa___DIAN_EKA_PUTRA_Pgl__DIAN', 'case_2025_TK1_Putusan_PA_Ngamprah_Nomor_1378_Pdt_G_2025_PA_Nph_Tanggal_25_Juni_2025__Penggugat_melawan_Tergugat']\n",
            "  Match score: 0.20\n",
            "\n",
            "MAJORITY Method:\n",
            "  Predicted: mengadili perkara-perkara pidana dalam tingkat banding, telah menjatuhkan putusan seperttersebut dib...\n",
            "  Confidence: 1.000\n",
            "  Top cases: ['case_2021_TK1_Putusan_PT_MATARAM_Nomor_120_PID_SUS_2021_PT_MTR_Tanggal_8_Nopember_2021__Pembanding_Terbanding_Terdakwa___RATNI__SH_Alias_RANITerbanding_Pembanding_Penuntut_Umum___FEDDY_HANTYO_NUG__M_H_', 'case_2021_TK1_Putusan_PT_PADANG_Nomor_70_PID_SUS_2021_PT_PDG_Tanggal_27_April_2021__Pembanding_Penuntut_Umum_I___MEILYA_TRISNA__SH__MHTerbanding_Terdakwa___DIAN_EKA_PUTRA_Pgl__DIAN', 'case_2025_TK1_Putusan_PA_Ngamprah_Nomor_1378_Pdt_G_2025_PA_Nph_Tanggal_25_Juni_2025__Penggugat_melawan_Tergugat']\n",
            "  Match score: 0.20\n",
            "\n",
            "--- DEMO_005 ---\n",
            "Query: perempuan muda dipaksa untuk bekerja di luar negeri di bawah ancaman kekerasan dan tanpa upah\n",
            "Expected: Terbukti bersalah, pidana penjara dan restitusi kepada korban\n",
            "\n",
            "WEIGHTED Method:\n",
            "  Predicted: amar putusan nomor.../pid.sus/2021/pt yyk direktori putusan putusan.mahkamahagung.go.id kepaniteraan...\n",
            "  Confidence: 0.066\n",
            "  Top cases: ['case_2021_TK1_Putusan_PT_YOGYAKARTA_Nomor_12_PID_SUS_2021_PT_YYK_Tanggal_18_Februari_2021__Pembanding_Penuntut_Umum___AGUS_KURNIAWAN_SHTerbanding_Terdakwa___SITI_FATIMAH_Als__NADIRA_Als__MBAK_MBUL', 'case_2021_TK1_Putusan_PN_SURABAYA_Nomor_575_Pid_Sus_2021_PN_Sby_Tanggal_24_Mei_2021__Penuntut_Umum_DZULKIFLY_NENTO__SHTerdakwa_RICO_LINGGAR_JAYA_BIN_EDI_WAHYONO', 'case_2021_TK1_Putusan_PN_PANGKALAN_BUN_Nomor_57_Pid_Sus_2021_PN_Pbu_Tanggal_7_April_2021__Penuntut_Umum_1_GOMGOMAN_H_SIMBOLON__S_H___M_H_2_GANES_ADI_KUSUMA__S_H_Terdakwa_RINDA_EVANNA_HOTMAULI_SIAIAHAAN']\n",
            "  Match score: 0.00\n",
            "\n",
            "MAJORITY Method:\n",
            "  Predicted: amar putusan nomor.../pid.sus/2021/pt yyk direktori putusan putusan.mahkamahagung.go.id kepaniteraan...\n",
            "  Confidence: 1.000\n",
            "  Top cases: ['case_2021_TK1_Putusan_PT_YOGYAKARTA_Nomor_12_PID_SUS_2021_PT_YYK_Tanggal_18_Februari_2021__Pembanding_Penuntut_Umum___AGUS_KURNIAWAN_SHTerbanding_Terdakwa___SITI_FATIMAH_Als__NADIRA_Als__MBAK_MBUL', 'case_2021_TK1_Putusan_PN_SURABAYA_Nomor_575_Pid_Sus_2021_PN_Sby_Tanggal_24_Mei_2021__Penuntut_Umum_DZULKIFLY_NENTO__SHTerdakwa_RICO_LINGGAR_JAYA_BIN_EDI_WAHYONO', 'case_2021_TK1_Putusan_PN_PANGKALAN_BUN_Nomor_57_Pid_Sus_2021_PN_Pbu_Tanggal_7_April_2021__Penuntut_Umum_1_GOMGOMAN_H_SIMBOLON__S_H___M_H_2_GANES_ADI_KUSUMA__S_H_Terdakwa_RINDA_EVANNA_HOTMAULI_SIAIAHAAN']\n",
            "  Match score: 0.00\n",
            "\n",
            "==================================================\n",
            "üìä v. OUTPUT\n",
            "==================================================\n",
            "üìÑ Predictions saved: predictions_20250626_073001.csv\n",
            "   Records: 10\n",
            "   Columns: ['query_id', 'query', 'method', 'predicted_solution', 'expected_outcome', 'top_5_case_ids', 'confidence', 'match_score', 'match_explanation']\n",
            "üìÑ Detailed results saved: detailed_predictions_20250626_073001.json\n",
            "\n",
            "======================================================================\n",
            "üîÆ TAHAP 4 - SOLUTION REUSE - SUMMARY REPORT\n",
            "======================================================================\n",
            "Generated: 2025-06-26 07:30:01\n",
            "\n",
            "üìä OVERALL STATISTICS:\n",
            "  Total predictions: 10\n",
            "  Successful predictions: 10 (100.0%)\n",
            "  Average confidence: 0.542\n",
            "  Average match score: 0.140\n",
            "\n",
            "üîß METHOD COMPARISON:\n",
            "  WEIGHTED:\n",
            "    Avg Confidence: 0.085\n",
            "    Avg Match Score: 0.120\n",
            "  MAJORITY:\n",
            "    Avg Confidence: 1.000\n",
            "    Avg Match Score: 0.160\n",
            "\n",
            "üèÜ BEST PREDICTIONS:\n",
            "  1. DEMO_001 (weighted)\n",
            "     Query: terdakwa merekrut dan mengirim perempuan ke luar n...\n",
            "     Match Score: 0.200\n",
            "     Confidence: 0.097\n",
            "  2. DEMO_001 (majority)\n",
            "     Query: terdakwa merekrut dan mengirim perempuan ke luar n...\n",
            "     Match Score: 0.200\n",
            "     Confidence: 1.000\n",
            "  3. DEMO_002 (majority)\n",
            "     Query: terdakwa memindahkan anak di bawah umur untuk dija...\n",
            "     Match Score: 0.200\n",
            "     Confidence: 1.000\n",
            "\n",
            "‚ùå POOR: System requires significant work\n",
            "======================================================================\n",
            "\n",
            "============================================================\n",
            "‚úÖ TAHAP 4 - SOLUTION REUSE COMPLETED!\n",
            "üìÅ Output files created:\n",
            "   - predictions_20250626_073001.csv\n",
            "   - detailed_predictions_20250626_073001.json\n",
            "üîÆ Solution reuse system ready for production!\n",
            "============================================================\n",
            "\n",
            "üéâ TAHAP 4 BERHASIL!\n",
            "‚ú® Yang telah diselesaikan:\n",
            "  ‚úÖ i. Ekstrak Solusi dari kasus top-k\n",
            "  ‚úÖ ii. Algoritma Prediksi (majority vote & weighted similarity)\n",
            "  ‚úÖ iii. Implementasi Fungsi predict_outcome()\n",
            "  ‚úÖ iv. Demo Manual dengan 5 contoh kasus\n",
            "  ‚úÖ v. Output CSV dan JSON hasil prediksi\n",
            "üîÆ Solution reuse system siap digunakan!\n"
          ]
        }
      ]
    }
  ]
}